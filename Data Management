nrow(application_train)
ncol(application_train)

## 20% of the overall sample size for test data
test_size <- floor(0.2 * nrow(application_train))
test_size

## set the seed to make your partition reproducible
set.seed(12345)
test_ind <- sample(seq_len(nrow(application_train)), size = test_size)

train_all <- application_train[-test_ind, ]
test <- application_train[test_ind, ]

## 20% of the train_all sample size for validation data
val_size <- floor(0.2 * nrow(train_all))
val_size

## set the seed to make your partition reproducible
set.seed(67890)
val_ind <- sample(seq_len(nrow(train_all)), size = val_size)

train <- train_all[-val_ind, ]
val <- train_all[val_ind, ]

#double check the number of obs
nrow(test)+nrow(train)+nrow(val)

#check variable type
var_type<-data.frame(sapply(application_train, class))
var_type <- cbind(rownames(var_type), var_type)
rownames(var_type) <- NULL

#check missing value
na_count <-sapply(application_train, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count  )

#extract variable with missing value
miss_var_list<-subset(na_count, na_count!=0)
miss_var_list <- cbind(rownames(miss_var_list), miss_var_list)
rownames(miss_var_list) <- NULL
miss_var_name<- data.frame(colnames(application_train)[apply(is.na(application_train), 2, any)])
colnames(miss_var_name)[1] <- "var_name"
miss_var_final<- merge (miss_var_list, miss_var_name)

#merge var with missing value and type
colnames(miss_var_list)[1] <- "var_name"
colnames(var_type)[1] <- "var_name"
miss_var<-merge (miss_var_list, var_type, by= "var_name")
colnames(miss_var)[3] <- "var_type"

#replace missing value for variables with very few missing values for training_all
#decide not to use it, instead of using missing.imputation function
#train_all_2<-train_all
#train_all_2$AMT_ANNUITY[is.na(train_all$AMT_ANNUITY)]<- round(mean(train_all$AMT_ANNUITY, na.rm = TRUE))
#train_all_2$CNT_FAM_MEMBERS[is.na(train_all$CNT_FAM_MEMBERS)]<- round(mean(train_all$CNT_FAM_MEMBERS, na.rm = TRUE))
#train_all_2$DAYS_LAST_PHONE_CHANGE[is.na(train_all$DAYS_LAST_PHONE_CHANGE)]<- round(mean(train_all$DAYS_LAST_PHONE_CHANGE, na.rm = TRUE))

#replace missing value of cagetorical variable with Unknow
cat_miss_var<-miss_var[which(miss_var$var_type=='character'),]

#table (train_all_2$EMERGENCYSTATE_MODE)
#table (train_all_2$FONDKAPREMONT_MODE)
#table (train_all_2$HOUSETYPE_MODE)
#table (train_all_2$NAME_TYPE_SUITE)
#table (train_all_2$OCCUPATION_TYPE)
#table (train_all_2$WALLSMATERIAL_MODE)

#train_all_2$EMERGENCYSTATE_MODE[is.na(train_all$EMERGENCYSTATE_MODE)]<- 'Unknown'
#train_all_2$FONDKAPREMONT_MODE[is.na(train_all$FONDKAPREMONT_MODE)]<- 'Unknown'
#train_all_2$HOUSETYPE_MODE[is.na(train_all$HOUSETYPE_MODE)]<- 'Unknown'
#train_all_2$NAME_TYPE_SUITE[is.na(train_all$NAME_TYPE_SUITE)]<- 'Unknown'
#train_all_2$OCCUPATION_TYPE[is.na(train_all$OCCUPATION_TYPE)]<- 'Unknown'
#train_all_2$WALLSMATERIAL_MODE[is.na(train_all$WALLSMATERIAL_MODE)]<- 'Unknown'

#missing data imputation function
missing.imputation <- function(var) {
  if (class(var)=="character") {
    var[is.na(var)] <- "Unknown"
  } else {
    var_new <- var
    var_new[!is.na(var_new)] <- var_new[!is.na(var_new)]- mean(var,na.rm=T)
    pval <- wilcox.test(na.omit(var_new),alternative="two.sided")$p.value
    if (pval<0.05) {
      var[is.na(var)] <- median(var,na.rm=T)
    } else {
      var[is.na(var)] <- mean(var,na.rm=T)
    }
  }
  return(var)
}

train_all_2 <- data.frame(missing.imputation(train_all[,1]),stringsAsFactors = F)
for (i in 2:ncol(train_all)) {
  train_all_2 <- cbind(train_all_2,data.frame(missing.imputation(train_all[,i]),stringsAsFactors = F))
}
colnames(train_all_2) <- colnames(train_all)

train_all_3 <- as.data.frame(train_all_2)
#drop ID and target var
train_all_hist <-train_all_3[,-1:-2]
#generate histograms of all continous variables
pdf("C:/Users/zhang/Desktop/MRM ML Workshop/Project 1/hist.pdf",width=9,height=9)
sapply(names(train_all_hist), function(cname){
  # (make sure we only plot the numeric columns)
  if (is.numeric(train_all_hist[[cname]]))
    # use the `main` param to put column name as plot title, turn off the x-axis label
    print(hist(train_all_hist[[cname]], main=cname,xlab=""))
})
dev.off()

#next step, examine the distributions of all numeric variables and identify potential outliers
#propose possible winsorization/variable collapse/binning
##Ignore all the 'FLAG_' variables, since they are binary even though they are numeric
train_all_4 <- train_all_3
numeric_var <- var_type[var_type[,2]=="numeric",]
#Cap number of children
train_all_4$CNT_CHILDREN[train_all_4$CNT_CHILDREN>4]<- 4
table (train_all_3$CNT_CHILDREN)
#cap AMT_INCOME_TOTAL
quantile(train_all_4$AMT_INCOME_TOTAL, probs = c(0,0.10, 0.25, 0.5, 0.75, 0.90,0.95, 0.99,1))
train_all_4$AMT_INCOME_TOTAL[train_all_4$AMT_INCOME_TOTAL>472500]<- quantile(train_all_4$AMT_INCOME_TOTAL,0.99)
# 0%       10%       25%       50%       75%       90%       95%       99%      100% 
# 25650     81000    112500    148500    202500    270000    337500    472500 117000000 
# 0%    10%    25%    50%    75%    90%    95%    99%   100% 
# 25650  81000 112500 148500 202500 270000 337500 472500 472500

quantile(train_all_4$AMT_CREDIT, probs = c(0,0.10, 0.25, 0.5, 0.75, 0.90,0.95, 0.99,1))
train_all_4$AMT_CREDIT[train_all_4$AMT_CREDIT>472500]<- quantile(train_all_4$AMT_CREDIT,0.99)
# 0%       10%       25%       50%       75%       90%       95%       99%      100% 
# 45000.0  180000.0  270000.0  514777.5  808650.0 1133748.0 1350000.0 1862802.0 4050000.0 
# 0%     10%     25%     50%     75%     90%     95%     99%    100% 
# 45000  180000  270000 1862802 1862802 1862802 1862802 1862802 1862802 

quantile(train_all_4$AMT_ANNUITY, probs = c(0,0.10, 0.25, 0.5, 0.75, 0.90,0.95, 0.99,1))
train_all_4$AMT_ANNUITY[train_all_4$AMT_ANNUITY>472500]<- quantile(train_all_4$AMT_ANNUITY,0.99)
# 0%      10%      25%      50%      75%      90%      95%      99%     100% 
# 1615.5  11047.5  16542.0  24925.5  34650.0  45954.0  53325.0  70006.5 258025.5 
# 0%      10%      25%      50%      75%      90%      95%      99%     100% 
# 1615.5  11047.5  16542.0  24925.5  34650.0  45954.0  53325.0  70006.5 258025.5 

#Check a couple of numeric variable in $ amount, it seems like 99% is a reasonable cap treatment
#Keep exploring others and discuss
